ğŸ“ Project Structure
Data_pipeline/
â”œâ”€â”€ cleaned_news_data.csv                 # Preprocessed news data
â”œâ”€â”€ consumer.py                           # Kafka consumer (local, receives user input)
â”œâ”€â”€ producer.py                           # Kafka producer (local, pushes data)
â”œâ”€â”€ preprocessing.py                      # Data cleaning and sentiment tagging logic
â”œâ”€â”€ data/
â”‚   â””â”€â”€ News_Articles.csv                 # Original dataset
â”œâ”€â”€ Instructions/                         # Screenshot instructions for UI
â”œâ”€â”€ news-sentiment-dashboard/            # Streamlit dashboard
â”‚   â”œâ”€â”€ app.py                            # Main dashboard app
â”‚   â”œâ”€â”€ config.toml                       # S3 and app settings
â”‚   â”œâ”€â”€ requirements.txt                  # Dependencies
â”‚   â””â”€â”€ readme.md                         # Internal dashboard readme

âš™ï¸ Key Components
1. Kafka Producer/Consumer (Local)
producer.py: Simulates or sends user-input articles to the Kafka topic.

consumer.py: Reads articles from Kafka and saves them for processing.

ğŸ”§ Runs on your local machine.

2. Preprocessing and Sentiment Analysis
preprocessing.py: Cleans the news data and adds a sentiment column using rule-based or ML logic.

Optionally runs on Databricks if needed for large-scale processing.

Saves results to an S3 bucket for access by the dashboard.

3. Streamlit Dashboard
Visualizes sentiment trends.

Includes word clouds, filtering by timestamp, and displays top positive/negative articles.

Loads sentiment data directly from your S3 bucket.

ğŸ–¥ï¸ Can be run locally with:

streamlit run news-sentiment-dashboard/app.py

ğŸš€ Running the Project
Install requirements (locally):

pip install -r news-sentiment-dashboard/requirements.txt
Start Kafka Producer & Consumer:

python producer.py
python consumer.py
Preprocess data:

python preprocessing.py
Run Streamlit Dashboard:

streamlit run news-sentiment-dashboard/app.py
â˜ï¸ Cloud & Integration
Databricks (optional): Used for large-scale sentiment processing.

S3 Bucket: Stores CSV files with sentiment results.

config.toml: Holds bucket name, region, and access configuration.

ğŸ“Š Dashboard Features
ğŸ“… Date range filter for articles
ğŸ“ˆ Sentiment distribution (bar chart)
ğŸŸ¢ Top Positive Articles
ğŸ”´ Top Negative Articles
â˜ï¸ Word Cloud of Frequent Words

ğŸ§  Future Enhancements
âœ… Integrate ML model to predict sentiment from user inputs
â±ï¸ Add real-time updates via Kafka streams
ğŸ³ Dockerize for deployment
Requirements
# Core dependencies
streamlit==1.32.2
pandas==2.2.1
numpy==1.26.4
matplotlib==3.8.3
wordcloud==1.9.3

# Kafka dependencies
kafka-python==2.0.2

# AWS S3 access
boto3==1.34.76
s3fs==2024.3.1
fsspec==2024.3.1

# Secret detection (optional for dev)
detect-secrets==1.4.0

# Spark support (optional for Databricks integration)
pyspark==3.5.1

To install all dependencies 
pip  install -r requirements.txt

get models to predict future unknown data
hinglish language
try to get model to predict on only english data and then try with hinglish data
you could get 100% and <70-80% accuracy\
can generate data by chatgpt

core ranking conference / journal